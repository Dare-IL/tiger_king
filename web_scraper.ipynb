{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Scraping images</h1>\n",
    "<p>We are going to build a neural network to classify big cats (Lions, Tigers, and Jaguars). To do this, we have to train the neural network on thousands of images of big cats so that it learns to classify them correctly. It would take <strong>hours</strong> to manually download thousands of images from the internet. Therefore we are going to scrape images.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part I: Download images</h1>\n",
    "<p>First let's import the necessary libraries.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request, urlretrieve\n",
    "import urllib\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I will be downloading images from <a href='https://www.dreamstime.com/photos-images/tiger.html'>dreamstime</a> which has many pages of images of big cats. To do this, I have defined the function below which takes in the following parameters:\n",
    "<ul> <li>animal_name: Name of the big cat so that dowloaded images can be correctly named.</li>\n",
    "    <li>start_link: The link to the first search page.</li>\n",
    "    <li>page_qty: Number of pages to scrape.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_images(animal_name, start_link, page_qty):\n",
    "    counter = 0\n",
    "    for num in range(1,page_qty+1):\n",
    "        page_link = start_link + str(num)\n",
    "        current_page = requests.get(page_link)\n",
    "        print(current_page)\n",
    "        #pause for a while\n",
    "        sleep(randint(8,15))\n",
    "        soup = BeautifulSoup(current_page.content, 'html.parser')\n",
    "        #extract relevant tag\n",
    "        animal = soup.find_all(class_=\"showonload\")    \n",
    "        animal_images = animal[0].find_all(\"img\") \n",
    "        #download all images on current page\n",
    "        for i in range(len(animal_images)):\n",
    "            web_links = animal_images[i]['data-src']\n",
    "            imgName = '%s%d.jpg'%(animal_name,counter)\n",
    "            try:\n",
    "                urllib.request.urlretrieve(web_links, imgName)\n",
    "                counter += 1\n",
    "            except:\n",
    "                print('Image Not Found')\n",
    "            \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I create two lists with the name of each cat and the link to the first page to download the images from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['jaguar', 'lion', 'tiger']\n",
    "links = ['https://www.dreamstime.com/search.php?srh_field=jaguar%20animal&s_all=n&s_ph=y&s_il=n&s_video=n&s_audio=n&s_ad=n&s_sl0=y&s_sl1=y&s_sl2=y&s_sl3=y&s_sl4=y&s_sl5=y&s_rf=y&s_ed=y&s_orp=y&s_orl=y&s_ors=y&s_orw=y&s_clc=y&s_clm=y&s_rsf=0&s_rst=7&s_st=new&s_sm=all&s_mrg=1&s_mrc1=y&s_mrc2=y&s_mrc3=y&s_mrc4=y&s_mrc5=y&s_exc=&pg=',\n",
    "        'https://www.dreamstime.com/search.php?srh_field=lion&s_all=n&s_ph=y&s_il=n&s_video=n&s_audio=n&s_ad=n&s_sl0=y&s_sl1=y&s_sl2=y&s_sl3=y&s_sl4=y&s_sl5=y&s_rf=y&s_ed=y&s_orp=y&s_orl=y&s_ors=y&s_orw=y&s_clc=y&s_clm=y&s_rsf=0&s_rst=7&s_st=new&s_sm=all&s_mrg=1&s_mrc1=y&s_mrc2=y&s_mrc3=y&s_mrc4=y&s_mrc5=y&s_exc=&pg=',\n",
    "        'https://www.dreamstime.com/photos-images/tiger.html?pg=']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now download pictures using the scrape_images function. Only download first 10 pages (approximately 800 pictures for each cat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "Image Not Found\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "number_images = []\n",
    "for i in range(3):\n",
    "    total= scrape_images(names[i], links[i], 10)\n",
    "    number_images.append(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part II: Organise data</h2>\n",
    "<p>Right now all the images are downloaded into same folder as the notebook. Let's split the images into a training and test set. 20% of the images will go in the test folder while the remaining 80% will be used to train the neural network.</p>\n",
    "<p>First, you need to create folders to store the training and test images. The folders need to be organised in the following format</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " dataset --> training_set-----> lion\n",
    "         |                 |--> jaguar\n",
    "         |                 |--> tiger\n",
    "         |\n",
    "         |--> test_set------> lion\n",
    "                          |--> jaguar\n",
    "                          |--> tiger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: dataset: File exists\n",
      "mkdir: dataset/training_set: File exists\n",
      "mkdir: dataset/training_set/lion: File exists\n",
      "mkdir: dataset/training_set/jaguar: File exists\n",
      "mkdir: dataset/training_set/tiger: File exists\n",
      "mkdir: dataset/test_set: File exists\n",
      "mkdir: dataset/test_set/lion: File exists\n",
      "mkdir: dataset/test_set/jaguar: File exists\n",
      "mkdir: dataset/test_set/tiger: File exists\n"
     ]
    }
   ],
   "source": [
    "%mkdir dataset\n",
    "%mkdir dataset/training_set\n",
    "%mkdir dataset/training_set/lion\n",
    "%mkdir dataset/training_set/jaguar\n",
    "%mkdir dataset/training_set/tiger\n",
    "%mkdir dataset/test_set\n",
    "%mkdir dataset/test_set/lion\n",
    "%mkdir dataset/test_set/jaguar\n",
    "%mkdir dataset/test_set/tiger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, string, os\n",
    "import random\n",
    "def organise_data(animal,total_pics):\n",
    "    if not os.path.exists('./dataset/test_set/%s'%animal):\n",
    "        print('There is no /dataset/test_set/%s folder '%animal)\n",
    "        return\n",
    "    elif not os.path.exists('./dataset/training_set/%s'%animal):\n",
    "        print('There is no /dataset/training_set/%s folder'%animal)\n",
    "        return             \n",
    "    else:                \n",
    "        end = int(0.2*total_pics)\n",
    "        test_data = random.sample(range(0, total_pics), end)\n",
    "        for number in test_data:\n",
    "            os.system('cp %s%s.jpg ./dataset/test_set/%s'%(animal,number,animal))\n",
    "            os.system('rm %s%s.jpg'%(animal,number))\n",
    "        os.system('cp %s* ./dataset/training_set/%s'%(animal,animal))\n",
    "        os.system('rm %s*'%(animal))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[796, 799, 799]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    organise_data(names[i],number_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
