{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "- train CNN on my own images + data augmentation\n",
    "- Fine tune pre-trained model and compare metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_arch, input_shape=(180, 180, 3), augment=False):\n",
    "    '''\n",
    "    Return a keras model with input architecture\n",
    "    Args:\n",
    "        model_arch: dict with no of filters, kernal, and pool size for each layer\n",
    "        input_shape: \n",
    "        Augment: bool to add data augmentation or not.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    inputs = keras.Input(shape=(input_shape))\n",
    "    \n",
    "    if augment:\n",
    "        data_aug = keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(0.1),\n",
    "            layers.RandomZoom(0.2),\n",
    "        ])\n",
    "        out = data_aug(inputs)\n",
    "    else:\n",
    "        out = inputs\n",
    "    \n",
    "    out = layers.Rescaling(1./255)(out)\n",
    "    \n",
    "    for layer in model_arch.keys():\n",
    "        filters = model_arch[layer]['filters']\n",
    "        k_size = model_arch[layer]['k_size']\n",
    "        p_size = model_arch[layer]['p_size']\n",
    "        out = layers.Conv2D(filters=filters, kernel_size=k_size, activation='relu')(out)\n",
    "        out = layers.MaxPooling2D(pool_size=p_size)(out)\n",
    "        \n",
    "    # always end with convolution and dense   \n",
    "    out = layers.Conv2D(filters=256, kernel_size=3, activation='relu')(out)\n",
    "    x = layers.Flatten()(out)\n",
    "    \n",
    "    # for augmented data use dropout to prevent overfitting\n",
    "    if augment:\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    outputs=layers.Dense(3, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = {'l2': {'filters': 32, 'k_size': 3, 'p_size': 2},\n",
    "              'l3': {'filters': 64, 'k_size': 3, 'p_size': 2},\n",
    "              'l4': {'filters': 128,'k_size': 3, 'p_size': 2},\n",
    "              'l5': {'filters': 256, 'k_size': 3, 'p_size': 2},\n",
    "#               'l6': {'filters': 256, 'k_size': 3, 'p_size': 2},\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset'\n",
    "train_dir = f'{data_dir}/training_set'\n",
    "test_dir = f'{data_dir}/test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (180, 180)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917 files belonging to 3 classes.\n",
      "Found 477 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = image_dataset_from_directory(train_dir, label_mode='categorical', image_size=image_size, batch_size=batch_size)\n",
    "test_data = image_dataset_from_directory(test_dir, label_mode='categorical', image_size=image_size, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2394"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1917+477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (32, 180, 180, 3)\n",
      "labels batch shape: (32, 3)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_data:\n",
    "    print(f'data batch shape: {data_batch.shape}')\n",
    "    print(f'labels batch shape: {labels_batch.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla CNN without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanila_model = build_model(model_arch, input_shape=(180, 180, 3), augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanila_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 178, 178, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 89, 89, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 87, 87, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 41, 41, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 37635     \n",
      "=================================================================\n",
      "Total params: 1,016,131\n",
      "Trainable params: 1,016,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vanila_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanila_callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='vanila_model.keras',\n",
    "        save_best_only=True,\n",
    "         monitor='val_loss'\n",
    "    )    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60/60 [==============================] - 225s 4s/step - loss: 1.1052 - accuracy: 0.4163 - val_loss: 0.9455 - val_accuracy: 0.5493\n",
      "Epoch 2/20\n",
      "60/60 [==============================] - 232s 4s/step - loss: 1.0068 - accuracy: 0.5456 - val_loss: 0.8559 - val_accuracy: 0.6017\n",
      "Epoch 3/20\n",
      "60/60 [==============================] - 233s 4s/step - loss: 0.9148 - accuracy: 0.5676 - val_loss: 0.7778 - val_accuracy: 0.6289\n",
      "Epoch 4/20\n",
      "60/60 [==============================] - 232s 4s/step - loss: 0.8876 - accuracy: 0.5989 - val_loss: 0.9736 - val_accuracy: 0.4927\n",
      "Epoch 5/20\n",
      "60/60 [==============================] - 232s 4s/step - loss: 0.7404 - accuracy: 0.6813 - val_loss: 0.6910 - val_accuracy: 0.6834\n",
      "Epoch 6/20\n",
      "60/60 [==============================] - 233s 4s/step - loss: 0.7231 - accuracy: 0.7011 - val_loss: 1.0485 - val_accuracy: 0.5157\n",
      "Epoch 7/20\n",
      "60/60 [==============================] - 234s 4s/step - loss: 0.6360 - accuracy: 0.7324 - val_loss: 0.7074 - val_accuracy: 0.7170\n",
      "Epoch 8/20\n",
      "60/60 [==============================] - 225s 4s/step - loss: 0.6134 - accuracy: 0.7590 - val_loss: 0.8493 - val_accuracy: 0.5996\n",
      "Epoch 9/20\n",
      "60/60 [==============================] - 233s 4s/step - loss: 0.5367 - accuracy: 0.7872 - val_loss: 0.9201 - val_accuracy: 0.5765\n",
      "Epoch 10/20\n",
      "60/60 [==============================] - 233s 4s/step - loss: 0.4989 - accuracy: 0.8106 - val_loss: 0.7577 - val_accuracy: 0.7212\n",
      "Epoch 11/20\n",
      "60/60 [==============================] - 236s 4s/step - loss: 0.4842 - accuracy: 0.8190 - val_loss: 0.6347 - val_accuracy: 0.7799\n",
      "Epoch 12/20\n",
      "60/60 [==============================] - 227s 4s/step - loss: 0.3869 - accuracy: 0.8472 - val_loss: 0.6793 - val_accuracy: 0.7945\n",
      "Epoch 13/20\n",
      "60/60 [==============================] - 225s 4s/step - loss: 0.3272 - accuracy: 0.8816 - val_loss: 1.3697 - val_accuracy: 0.6939\n",
      "Epoch 14/20\n",
      "60/60 [==============================] - 226s 4s/step - loss: 0.3416 - accuracy: 0.8816 - val_loss: 0.7369 - val_accuracy: 0.7526\n",
      "Epoch 15/20\n",
      "60/60 [==============================] - 228s 4s/step - loss: 0.2311 - accuracy: 0.9191 - val_loss: 0.6632 - val_accuracy: 0.7757\n",
      "Epoch 16/20\n",
      "60/60 [==============================] - 224s 4s/step - loss: 0.1758 - accuracy: 0.9416 - val_loss: 0.7968 - val_accuracy: 0.8029\n",
      "Epoch 17/20\n",
      "60/60 [==============================] - 225s 4s/step - loss: 0.2250 - accuracy: 0.9228 - val_loss: 0.9345 - val_accuracy: 0.7757\n",
      "Epoch 18/20\n",
      "60/60 [==============================] - 223s 4s/step - loss: 0.1845 - accuracy: 0.9546 - val_loss: 1.1282 - val_accuracy: 0.7233\n",
      "Epoch 19/20\n",
      "60/60 [==============================] - 231s 4s/step - loss: 0.1486 - accuracy: 0.9536 - val_loss: 1.1958 - val_accuracy: 0.5681\n",
      "Epoch 20/20\n",
      "60/60 [==============================] - 219s 4s/step - loss: 0.1555 - accuracy: 0.9588 - val_loss: 1.3323 - val_accuracy: 0.7505\n"
     ]
    }
   ],
   "source": [
    "vanila_history = vanila_model.fit(\n",
    " train_data,\n",
    "    epochs=20,\n",
    "    validation_data=test_data,\n",
    "    callbacks=vanila_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model is severly overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with data augmentation and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_model = build_model(model_arch, input_shape=(180, 180, 3), augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_1 (Rescaling)      (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 178, 178, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 89, 89, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 87, 87, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 41, 41, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 37635     \n",
      "=================================================================\n",
      "Total params: 1,016,131\n",
      "Trainable params: 1,016,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aug_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='data_aug_model.keras',\n",
    "        save_best_only=True,\n",
    "         monitor='val_loss'\n",
    "    )    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60/60 [==============================] - 235s 4s/step - loss: 1.1998 - accuracy: 0.3792 - val_loss: 1.0578 - val_accuracy: 0.4528\n",
      "Epoch 2/20\n",
      "60/60 [==============================] - 234s 4s/step - loss: 1.1151 - accuracy: 0.4356 - val_loss: 1.0269 - val_accuracy: 0.4675\n",
      "Epoch 3/20\n",
      "60/60 [==============================] - 233s 4s/step - loss: 1.0515 - accuracy: 0.4872 - val_loss: 0.9663 - val_accuracy: 0.5472\n",
      "Epoch 4/20\n",
      "60/60 [==============================] - 230s 4s/step - loss: 0.9982 - accuracy: 0.5352 - val_loss: 0.9176 - val_accuracy: 0.5556\n",
      "Epoch 5/20\n",
      "60/60 [==============================] - 230s 4s/step - loss: 0.9608 - accuracy: 0.5623 - val_loss: 0.8995 - val_accuracy: 0.5493\n",
      "Epoch 6/20\n",
      "60/60 [==============================] - 229s 4s/step - loss: 0.9288 - accuracy: 0.5686 - val_loss: 0.9085 - val_accuracy: 0.5556\n",
      "Epoch 7/20\n",
      "60/60 [==============================] - 222s 4s/step - loss: 0.9011 - accuracy: 0.6020 - val_loss: 0.8464 - val_accuracy: 0.6143\n",
      "Epoch 8/20\n",
      "60/60 [==============================] - 220s 4s/step - loss: 0.8544 - accuracy: 0.6333 - val_loss: 1.0604 - val_accuracy: 0.5577\n",
      "Epoch 9/20\n",
      "60/60 [==============================] - 229s 4s/step - loss: 0.8145 - accuracy: 0.6541 - val_loss: 0.8669 - val_accuracy: 0.6604\n",
      "Epoch 10/20\n",
      "60/60 [==============================] - 234s 4s/step - loss: 0.8101 - accuracy: 0.6761 - val_loss: 0.8940 - val_accuracy: 0.5849\n",
      "Epoch 11/20\n",
      "60/60 [==============================] - 230s 4s/step - loss: 0.7600 - accuracy: 0.6688 - val_loss: 1.3940 - val_accuracy: 0.5493\n",
      "Epoch 12/20\n",
      "60/60 [==============================] - 230s 4s/step - loss: 0.7278 - accuracy: 0.7089 - val_loss: 0.7666 - val_accuracy: 0.6583\n",
      "Epoch 13/20\n",
      "60/60 [==============================] - 230s 4s/step - loss: 0.7096 - accuracy: 0.7068 - val_loss: 0.8945 - val_accuracy: 0.6059\n",
      "Epoch 14/20\n",
      "60/60 [==============================] - 230s 4s/step - loss: 0.7039 - accuracy: 0.7235 - val_loss: 0.8846 - val_accuracy: 0.5639\n",
      "Epoch 15/20\n",
      "60/60 [==============================] - 230s 4s/step - loss: 0.6278 - accuracy: 0.7454 - val_loss: 0.7544 - val_accuracy: 0.6101\n",
      "Epoch 16/20\n",
      "60/60 [==============================] - 230s 4s/step - loss: 0.6068 - accuracy: 0.7564 - val_loss: 1.8815 - val_accuracy: 0.5304\n",
      "Epoch 17/20\n",
      "60/60 [==============================] - 231s 4s/step - loss: 0.6097 - accuracy: 0.7600 - val_loss: 0.9537 - val_accuracy: 0.6876\n",
      "Epoch 18/20\n",
      "60/60 [==============================] - 232s 4s/step - loss: 0.5695 - accuracy: 0.7799 - val_loss: 1.2806 - val_accuracy: 0.6709\n",
      "Epoch 19/20\n",
      "60/60 [==============================] - 231s 4s/step - loss: 0.6403 - accuracy: 0.7606 - val_loss: 0.6928 - val_accuracy: 0.7421\n",
      "Epoch 20/20\n",
      "60/60 [==============================] - 231s 4s/step - loss: 0.4979 - accuracy: 0.8007 - val_loss: 0.7716 - val_accuracy: 0.6960\n"
     ]
    }
   ],
   "source": [
    "aug_history = aug_model.fit(\n",
    " train_data,\n",
    "    epochs=20,\n",
    "    validation_data=test_data,\n",
    "    callbacks=aug_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Less severe overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction from pre-trained model\n",
    "- no data augmentation\n",
    "- VGG16 model: Use only convolution layers (convolutional base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 36s 1us/step\n",
      "58900480/58889256 [==============================] - 36s 1us/step\n"
     ]
    }
   ],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(180,180,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 180, 180, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 180, 180, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 90, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 90, 90, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 90, 90, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 45, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 45, 45, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 45, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 45, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 22, 22, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_labels(conv_base, \n",
    "                        dataset,\n",
    "                        preproc=keras.applications.vgg16.preprocess_input, \n",
    "                        ):\n",
    "    features, labels = [], []\n",
    "    \n",
    "    for img, label in dataset:\n",
    "        img_proc = preproc(img)\n",
    "        feat = conv_base.predict(img_proc)\n",
    "        features.append(feat)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return np.concatenate(features), np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = get_features_labels(conv_base, train_data)\n",
    "val_features, val_labels = get_features_labels(conv_base, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(5,5,512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "pre_model = keras.Model(inputs, outputs)\n",
    "\n",
    "pre_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    ")\n",
    "pre_callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='feature_extraction_model.keras',\n",
    "        save_best_only=True,\n",
    "         monitor='val_loss'\n",
    "    )    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60/60 [==============================] - 4s 49ms/step - loss: 37.4633 - accuracy: 0.8492 - val_loss: 48.6045 - val_accuracy: 0.8176\n",
      "Epoch 2/20\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 13.7522 - accuracy: 0.9249 - val_loss: 25.9691 - val_accuracy: 0.8889\n",
      "Epoch 3/20\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 4.8065 - accuracy: 0.9656 - val_loss: 29.3873 - val_accuracy: 0.8931\n",
      "Epoch 4/20\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 4.0321 - accuracy: 0.9682 - val_loss: 20.5796 - val_accuracy: 0.9099\n",
      "Epoch 5/20\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 4.4934 - accuracy: 0.9781 - val_loss: 24.3533 - val_accuracy: 0.9119\n",
      "Epoch 6/20\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 2.2831 - accuracy: 0.9844 - val_loss: 23.7965 - val_accuracy: 0.9140\n",
      "Epoch 7/20\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 1.6031 - accuracy: 0.9849 - val_loss: 26.5460 - val_accuracy: 0.9182\n",
      "Epoch 8/20\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 2.6043 - accuracy: 0.9890 - val_loss: 26.5907 - val_accuracy: 0.9182\n",
      "Epoch 9/20\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 1.0829 - accuracy: 0.9890 - val_loss: 26.5257 - val_accuracy: 0.9287\n",
      "Epoch 10/20\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 1.1803 - accuracy: 0.9911 - val_loss: 38.6636 - val_accuracy: 0.8994\n",
      "Epoch 11/20\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 2.3897 - accuracy: 0.9880 - val_loss: 29.4367 - val_accuracy: 0.9182\n",
      "Epoch 12/20\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 1.5268 - accuracy: 0.9911 - val_loss: 29.5224 - val_accuracy: 0.9203\n",
      "Epoch 13/20\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.6124 - accuracy: 0.9943 - val_loss: 26.6721 - val_accuracy: 0.9078\n",
      "Epoch 14/20\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 1.3628 - accuracy: 0.9937 - val_loss: 34.8664 - val_accuracy: 0.9182\n",
      "Epoch 15/20\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 1.0654 - accuracy: 0.9953 - val_loss: 24.2107 - val_accuracy: 0.9203\n",
      "Epoch 16/20\n",
      "60/60 [==============================] - 3s 46ms/step - loss: 1.0322 - accuracy: 0.9963 - val_loss: 28.3127 - val_accuracy: 0.9015\n",
      "Epoch 17/20\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 1.7193 - accuracy: 0.9927 - val_loss: 31.5107 - val_accuracy: 0.9161\n",
      "Epoch 18/20\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 1.0132 - accuracy: 0.9927 - val_loss: 30.6505 - val_accuracy: 0.9119\n",
      "Epoch 19/20\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 1.4855 - accuracy: 0.9917 - val_loss: 27.4893 - val_accuracy: 0.9140\n",
      "Epoch 20/20\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 1.7198 - accuracy: 0.9937 - val_loss: 30.8352 - val_accuracy: 0.9224\n"
     ]
    }
   ],
   "source": [
    "pre_history = pre_model.fit(\n",
    " train_features, train_labels,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    callbacks=pre_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher train accuracy and less overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
